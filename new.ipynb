{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69746748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f10789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drugs: (30056, 1024)\n",
      "Proteins: (30056, 20000)\n",
      "Labels: (30056, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "X_drug = np.load(\"X_drug.npy\")       # shape (samples, 1024)\n",
    "X_protein = np.load(\"X_protein.npy\") # shape (samples, 20000)\n",
    "y = np.load(\"y.npy\")                 # shape (samples, 1)\n",
    "\n",
    "print(\"Drugs:\", X_drug.shape)\n",
    "print(\"Proteins:\", X_protein.shape)\n",
    "print(\"Labels:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTADataset(Dataset):\n",
    "    def __init__(self, X_drug, X_protein, y):\n",
    "        self.X_drug = torch.tensor(X_drug, dtype=torch.float32)\n",
    "        self.X_protein = torch.tensor(X_protein, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_drug[idx], self.X_protein[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c39467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 24044, Test size: 6012\n"
     ]
    }
   ],
   "source": [
    "dataset = DTADataset(X_drug, X_protein, y)\n",
    "\n",
    "# 80-20 split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41d8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDTA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepDTA, self).__init__()\n",
    "\n",
    "        # Drug CNN\n",
    "        self.drug_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Protein CNN\n",
    "        self.protein_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*252 + 64*4996, 1024), # adjust sizes dynamically\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)  # regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, drug, protein):\n",
    "        # Reshape to (batch, channel=1, length)\n",
    "        drug = drug.unsqueeze(1)\n",
    "        protein = protein.unsqueeze(1)\n",
    "\n",
    "        drug_feat = self.drug_cnn(drug)\n",
    "        protein_feat = self.protein_cnn(protein)\n",
    "\n",
    "        combined = torch.cat((drug_feat, protein_feat), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181a2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDTA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepDTA, self).__init__()\n",
    "\n",
    "        # Drug CNN\n",
    "        self.drug_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # Protein CNN\n",
    "        self.protein_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        # ðŸ”¹ Dynamically determine feature size\n",
    "        with torch.no_grad():\n",
    "            dummy_drug = torch.zeros(1, 1, 1024)     # (batch=1, channel=1, drug_len=1024)\n",
    "            dummy_protein = torch.zeros(1, 1, 20000) # (batch=1, channel=1, prot_len=20000)\n",
    "\n",
    "            drug_feat = self.drug_cnn(dummy_drug)\n",
    "            protein_feat = self.protein_cnn(dummy_protein)\n",
    "\n",
    "            combined_dim = drug_feat.shape[1] + protein_feat.shape[1]\n",
    "            print(\"âœ… Combined feature dim:\", combined_dim)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, drug, protein):\n",
    "        drug = drug.unsqueeze(1)       # (batch, 1, 1024)\n",
    "        protein = protein.unsqueeze(1) # (batch, 1, 20000)\n",
    "\n",
    "        drug_feat = self.drug_cnn(drug)\n",
    "        protein_feat = self.protein_cnn(protein)\n",
    "\n",
    "        combined = torch.cat((drug_feat, protein_feat), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8170dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined feature dim: 335616\n",
      "Epoch 1/10, Loss: 22345942.5922\n",
      "Epoch 2/10, Loss: 16501151.9162\n",
      "Epoch 3/10, Loss: 15356083.5187\n",
      "Epoch 4/10, Loss: 13440187.4793\n",
      "Epoch 5/10, Loss: 12604278.0251\n",
      "Epoch 6/10, Loss: 12121851.4896\n",
      "Epoch 7/10, Loss: 11666248.0245\n",
      "Epoch 8/10, Loss: 11350930.7425\n",
      "Epoch 9/10, Loss: 11033974.7203\n",
      "Epoch 10/10, Loss: 10766962.1280\n"
     ]
    }
   ],
   "source": [
    "model = DeepDTA().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_drug, batch_protein, batch_y in train_loader:\n",
    "        batch_drug, batch_protein, batch_y = batch_drug.to(device), batch_protein.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_drug, batch_protein)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_drug.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beef58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test RMSE: 3239.7460288327115\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mse, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch_drug, batch_protein, batch_y in test_loader:\n",
    "        batch_drug, batch_protein, batch_y = batch_drug.to(device), batch_protein.to(device), batch_y.to(device)\n",
    "        preds = model(batch_drug, batch_protein)\n",
    "        mse += criterion(preds, batch_y).item() * batch_drug.size(0)\n",
    "        total += batch_drug.size(0)\n",
    "\n",
    "test_rmse = np.sqrt(mse / total)\n",
    "print(\"âœ… Test RMSE:\", test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd16580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Binding Affinity: 1848.3349609375\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    drug_sample = torch.rand(1, 1024).to(device)     # Example random drug fingerprint\n",
    "    protein_sample = torch.rand(1, 20000).to(device) # Example random protein sequence encoding\n",
    "\n",
    "    pred = model(drug_sample, protein_sample)\n",
    "print(\"Predicted Binding Affinity:\", pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7e283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Combined feature dim: 335616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepDTA(\n",
       "  (drug_cnn): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(8,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(32, 64, kernel_size=(8,), stride=(1,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (protein_cnn): Sequential(\n",
       "    (0): Conv1d(1, 32, kernel_size=(8,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(32, 64, kernel_size=(8,), stride=(1,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=335616, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"deepdta_model.pth\")\n",
    "\n",
    "# Later load it\n",
    "model = DeepDTA().to(device)\n",
    "model.load_state_dict(torch.load(\"deepdta_model.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641ec15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Binding Affinity: 3924.860595703125\n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a new drug fingerprint (size=1024)\n",
    "custom_drug = np.random.rand(1024)\n",
    "custom_protein = np.random.rand(20000)\n",
    "\n",
    "drug_tensor = torch.tensor(custom_drug, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "protein_tensor = torch.tensor(custom_protein, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(drug_tensor, protein_tensor)\n",
    "\n",
    "print(\"Predicted Binding Affinity:\", pred.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5843d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
