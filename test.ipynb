{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d35daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Load drugs (SMILES)\n",
    "with open(\"ligands.txt\") as f:\n",
    "    drugs = [line.strip() for line in f]\n",
    "\n",
    "# Load proteins (sequences)\n",
    "with open(\"proteins.txt\") as f:\n",
    "    proteins = [line.strip() for line in f]\n",
    "\n",
    "# Load affinity matrix (usually in .npy or .pkl format in Davis repo)\n",
    "Y = np.loadtxt(\"affinity.txt\")   # shape = (num_drugs, num_proteins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0bbb776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affinity matrix shape: (68, 442)\n"
     ]
    }
   ],
   "source": [
    "print(\"Affinity matrix shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2879ce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.3e+01 1.0e+04 1.0e+04 1.0e+04 1.0e+04]\n",
      " [1.0e+04 1.0e+04 1.0e+04 1.0e+04 1.0e+04]\n",
      " [1.0e+04 7.5e+01 1.9e+00 1.3e+01 7.7e-01]\n",
      " [1.0e+04 1.0e+04 1.0e+04 1.0e+04 1.0e+04]\n",
      " [1.0e+04 4.2e+02 2.9e+03 7.5e+02 5.8e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(Y[:5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc43c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 442 proteins\n",
      "Example: AAK1 -> MKKFFDSRREQGGSGLGSGSSGGGGSTSGL...\n",
      "Proteins shape: (442, 20000)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load proteins.json (actually your proteins.txt)\n",
    "with open(\"proteins.txt\") as f:\n",
    "    proteins_dict = json.load(f)\n",
    "\n",
    "# Extract sequences and IDs\n",
    "proteins = list(proteins_dict.values())\n",
    "protein_ids = list(proteins_dict.keys())\n",
    "\n",
    "print(f\"✅ Loaded {len(proteins)} proteins\")\n",
    "print(\"Example:\", protein_ids[0], \"->\", proteins[0][:30] + \"...\")\n",
    "\n",
    "# One-hot encoding of protein sequences (simple example)\n",
    "# Here we just pad/truncate to 1000 chars\n",
    "MAX_SEQ_LEN = 1000\n",
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"  # 20 standard aa\n",
    "aa_to_idx = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "def encode_protein(seq):\n",
    "    arr = np.zeros((MAX_SEQ_LEN, len(AMINO_ACIDS)), dtype=int)\n",
    "    for i, aa in enumerate(seq[:MAX_SEQ_LEN]):\n",
    "        if aa in aa_to_idx:\n",
    "            arr[i, aa_to_idx[aa]] = 1\n",
    "    return arr.flatten()\n",
    "\n",
    "X_protein = np.array([encode_protein(seq) for seq in proteins])\n",
    "\n",
    "print(\"Proteins shape:\", X_protein.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3fd804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 68 ligands\n",
      "Example: 11314340 -> CC1=C2C=C(C=CC2=NN1)C3=CC(=CN=C3)OCC(CC4=CC=CC=C4)...\n",
      "Drugs shape: (68, 1024)\n",
      "✅ Loaded 442 proteins\n",
      "Example: AAK1 -> MKKFFDSRREQGGSGLGSGSSGGGGSTSGLGSGYIGRVFGIGRQQVTVDE...\n",
      "Proteins shape: (442, 20000)\n",
      "Affinity matrix shape: (68, 442)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n",
      "[10:56:11] DEPRECATION WARNING: please use MorganGenerator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples created: 30056\n",
      "Drugs shape: (30056, 1024)\n",
      "Proteins shape: (30056, 20000)\n",
      "Labels shape: (30056, 1)\n",
      "🎉 Preprocessing complete! Files saved: X_drug.npy, X_protein.npy, y.npy\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# DeepDTA Preprocessing Full Code\n",
    "# -------------------------------\n",
    "import json\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Load ligands (drugs)\n",
    "# -------------------------------\n",
    "with open(\"ligands.txt\") as f:\n",
    "    ligands_dict = json.load(f)   # full JSON\n",
    "\n",
    "drug_ids = list(ligands_dict.keys())\n",
    "drugs = list(ligands_dict.values())\n",
    "print(f\"✅ Loaded {len(drugs)} ligands\")\n",
    "print(\"Example:\", drug_ids[0], \"->\", drugs[0][:50] + \"...\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Convert SMILES → Morgan Fingerprints\n",
    "# -------------------------------\n",
    "def smiles_to_fp(smiles, radius=2, nBits=1024):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n",
    "        arr = np.zeros((nBits,), dtype=int)\n",
    "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "        return arr\n",
    "    else:\n",
    "        print(\"⚠️ Failed to parse:\", smiles)\n",
    "        return np.zeros((nBits,), dtype=int)\n",
    "\n",
    "X_drug = np.array([smiles_to_fp(smi) for smi in drugs])\n",
    "print(\"Drugs shape:\", X_drug.shape)  # should be (68, 1024)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Load proteins\n",
    "# -------------------------------\n",
    "with open(\"proteins.txt\") as f:\n",
    "    proteins_dict = json.load(f)\n",
    "\n",
    "protein_ids = list(proteins_dict.keys())\n",
    "proteins = list(proteins_dict.values())\n",
    "print(f\"✅ Loaded {len(proteins)} proteins\")\n",
    "print(\"Example:\", protein_ids[0], \"->\", proteins[0][:50] + \"...\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Convert protein sequences → one-hot (flattened)\n",
    "# -------------------------------\n",
    "MAX_SEQ_LEN = 1000\n",
    "AMINO_ACIDS = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "aa_to_idx = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "def encode_protein(seq):\n",
    "    arr = np.zeros((MAX_SEQ_LEN, len(AMINO_ACIDS)), dtype=int)\n",
    "    for i, aa in enumerate(seq[:MAX_SEQ_LEN]):\n",
    "        if aa in aa_to_idx:\n",
    "            arr[i, aa_to_idx[aa]] = 1\n",
    "    return arr.flatten()\n",
    "\n",
    "X_protein = np.array([encode_protein(seq) for seq in proteins])\n",
    "print(\"Proteins shape:\", X_protein.shape)  # (442, 20000)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Load affinity matrix\n",
    "# -------------------------------\n",
    "Y = np.loadtxt(\"affinity.txt\")  # shape = (68, 442)\n",
    "print(\"Affinity matrix shape:\", Y.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Create (drug, protein, affinity) triplets\n",
    "# -------------------------------\n",
    "data = []\n",
    "for i in range(X_drug.shape[0]):        # 68 drugs\n",
    "    for j in range(X_protein.shape[0]): # 442 proteins\n",
    "        data.append((X_drug[i], X_protein[j], Y[i,j]))\n",
    "\n",
    "X_drug_all = np.array([d for d, p, y in data])\n",
    "X_protein_all = np.array([p for d, p, y in data])\n",
    "y_all = np.array([y for d, p, y in data]).reshape(-1, 1)\n",
    "\n",
    "print(\"Total samples created:\", X_drug_all.shape[0])\n",
    "print(\"Drugs shape:\", X_drug_all.shape)\n",
    "print(\"Proteins shape:\", X_protein_all.shape)\n",
    "print(\"Labels shape:\", y_all.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Save preprocessed data\n",
    "# -------------------------------\n",
    "np.save(\"X_drug.npy\", X_drug_all)\n",
    "np.save(\"X_protein.npy\", X_protein_all)\n",
    "np.save(\"y.npy\", y_all)\n",
    "print(\"🎉 Preprocessing complete! Files saved: X_drug.npy, X_protein.npy, y.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1827a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb5ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drug = np.load(\"X_drug.npy\")        # shape: (30056, 1024)\n",
    "X_protein = np.load(\"X_protein.npy\")  # shape: (30056, 20000)\n",
    "y = np.load(\"y.npy\")                  # shape: (30056, 1)\n",
    "\n",
    "# Standardize labels (optional, helps training)\n",
    "scaler = StandardScaler()\n",
    "y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f224451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drug_train, X_drug_test, X_protein_train, X_protein_test, y_train, y_test = train_test_split(\n",
    "    X_drug, X_protein, y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cf782af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTADataset(Dataset):\n",
    "    def __init__(self, X_drug, X_protein, y):\n",
    "        self.X_drug = torch.tensor(X_drug, dtype=torch.float32)\n",
    "        self.X_protein = torch.tensor(X_protein, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_drug[idx], self.X_protein[idx], self.y[idx]\n",
    "\n",
    "train_dataset = DTADataset(X_drug_train, X_protein_train, y_train)\n",
    "test_dataset = DTADataset(X_drug_test, X_protein_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44873b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDTA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepDTA, self).__init__()\n",
    "        \n",
    "        # Drug branch\n",
    "        self.drug_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            nn.Conv1d(32, 64, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4)\n",
    "        )\n",
    "        \n",
    "        # Protein branch\n",
    "        self.protein_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4),\n",
    "            nn.Conv1d(32, 64, kernel_size=8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4)\n",
    "        )\n",
    "        \n",
    "        # Dummy input to compute flattened size\n",
    "        self._to_linear = None\n",
    "        self._compute_flattened_size()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self._to_linear, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def _compute_flattened_size(self):\n",
    "        # create dummy tensors\n",
    "        x_drug = torch.zeros(1, 1, 1024)\n",
    "        x_protein = torch.zeros(1, 1, 20000)\n",
    "        \n",
    "        drug_feat = self.drug_cnn(x_drug)\n",
    "        protein_feat = self.protein_cnn(x_protein)\n",
    "        \n",
    "        self._to_linear = drug_feat.view(1, -1).shape[1] + protein_feat.view(1, -1).shape[1]\n",
    "    \n",
    "    def forward(self, drug, protein):\n",
    "        drug = drug.unsqueeze(1)       # (batch, 1, 1024)\n",
    "        protein = protein.unsqueeze(1) # (batch, 1, 20000)\n",
    "        \n",
    "        drug_feat = self.drug_cnn(drug)\n",
    "        drug_feat = drug_feat.view(drug_feat.size(0), -1)\n",
    "        \n",
    "        protein_feat = self.protein_cnn(protein)\n",
    "        protein_feat = protein_feat.view(protein_feat.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([drug_feat, protein_feat], dim=1)\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04709ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepDTA().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67eb230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8652\n",
      "Epoch 2/10, Loss: 0.5845\n",
      "Epoch 3/10, Loss: 0.5306\n",
      "Epoch 4/10, Loss: 0.4682\n",
      "Epoch 5/10, Loss: 0.4148\n",
      "Epoch 6/10, Loss: 0.3735\n",
      "Epoch 7/10, Loss: 0.3357\n",
      "Epoch 8/10, Loss: 0.2989\n",
      "Epoch 9/10, Loss: 0.2603\n",
      "Epoch 10/10, Loss: 0.2272\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_drug, batch_protein, batch_y in train_loader:\n",
    "        batch_drug = batch_drug.to(device)\n",
    "        batch_protein = batch_protein.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_drug, batch_protein)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_drug.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c84076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2623.6458\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, trues = [], []\n",
    "with torch.no_grad():\n",
    "    for batch_drug, batch_protein, batch_y in test_loader:\n",
    "        batch_drug = batch_drug.to(device)\n",
    "        batch_protein = batch_protein.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        outputs = model(batch_drug, batch_protein)\n",
    "        preds.append(outputs.cpu().numpy())\n",
    "        trues.append(batch_y.cpu().numpy())\n",
    "\n",
    "preds = np.vstack(preds)\n",
    "trues = np.vstack(trues)\n",
    "\n",
    "# Inverse scaling\n",
    "preds = scaler.inverse_transform(preds)\n",
    "trues = scaler.inverse_transform(trues)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(np.mean((preds - trues)**2))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdf0de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.load(\"y.npy\")  # original labels\n",
    "y = np.log(y + 1e-8)  # add small epsilon to avoid log(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85c36d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   43.00000001]\n",
      " [10000.00000001]\n",
      " [10000.00000001]\n",
      " ...\n",
      " [ 1900.00000001]\n",
      " [ 4400.00000001]\n",
      " [10000.00000001]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_original = np.exp(y)\n",
    "print(y_pred_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8898485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
